<!DOCTYPE html>
<html lang="en-us">
<head>
    <title>Mauro Abidal Carrer - Artificial Intelligence</title>    
    <link href="./index.css" rel="stylesheet">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="Mauro Abidal">
    <meta name="description" content="Artificial Intelligence Portfolio">
    <meta name="keywords" content="Mauro, Mauro Abidal, Artificial Intelligence, Machine Learning">
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <link rel="icon" type="image/x-icon" href="./resources/galaxy.png">
</head>
<body>
    <header>
        <h1>Mauro Abidal - Artificial Intelligence Projects</h1>
        <nav>
            <ul>
                <li><a href="./game-development.html">Game Development</a></li>
            </ul>
        </nav>
    </header>
    <div class="container">
		<section>
			<p>
			Hi, my name is Mauro, I study computer science at <a href="https://42.fr/en/homepage/" target="_blank">42school</a>, Paris.<br>
			I started programming in 2019 to make games and <a href="#robot" style="scroll-behavior: smooth;">robots</a>.<br>
            After working on video game projects and school projects    
			email: <a href="mailto:mauroabidal@yahoo.fr">mauroabidal@yahoo.fr</a><br>
			discord: Kantic
			</p>
        <h1 id="artificial-intelligence">Artificial Intelligence Projects</h1>
        <section>
            <article>
                <h2>Trash Object Localization on TACO Dataset</h2>
                <img src="https://raw.githubusercontent.com/wiki/pedropro/TACO/images/logonav.png" alt="TACO Dataset Image">
                <p>
                    <i>
                        TACO is a growing image dataset of waste in the wild.
                        It contains images of litter taken under diverse environments: woods, roads and beaches.
                        These images are manually labeled and segmented according to a hierarchical taxonomy to train and evaluate object detection algorithms.
                        Currently, images are hosted on Flickr and we have a server that is collecting more images and annotations @ tacodataset.org
                    </i>
                </p>
                <p>
                    An ongoing toy project to learn how to train a computer vision model and curate a computer vision dataset.<br>
                    GitHub: <a href="https://github.com/MauroAbidalCarrer/DL_waste_computer_vision/tree/main" target="_blank">https://github.com/MauroAbidalCarrer/DL_waste_computer_vision/tree/main</a>
                </p>
                <img src="https://images.prismic.io/encord/ef01e416-70ed-4f19-a477-eea8f249b632_TACO-image+%2815%29.webp?auto=compress,format" alt="TACO Dataset Image">
                <p>
                    TACO is a dataset of annotated images of multiple types of trash objects.
                </p>
            </article>
            <article>
                <h2>Participation in an Open Source Project</h2>
                <p>
                    I have participated in the local-code-interpreter project.<br>
                    It is a code interpreter project in which I added the functionality to serialize (and deserialize) the conversation in a notebook.<br>
                    I also added "conversation slicing", that is, omitting parts of the conversation when feeding it to the LLM.<br>
                    This is to maintain the conversation size within the LLM context window and reduce the cost of the LLM.<br>
                    GitHub: <a href="https://github.com/MrGreyfun/Local-Code-Interpreter" target="_blank">https://github.com/MrGreyfun/Local-Code-Interpreter</a><br>
                    Serialization PR: <a href="https://github.com/MrGreyfun/Local-Code-Interpreter/pull/24" target="_blank">https://github.com/MrGreyfun/Local-Code-Interpreter/pull/24</a><br>
                    Conversation Slicing PR: <a href="https://github.com/MrGreyfun/Local-Code-Interpreter/pull/32" target="_blank">https://github.com/MrGreyfun/Local-Code-Interpreter/pull/32</a><br>
                    Deserialization PR (still open): <a href="https://github.com/MrGreyfun/Local-Code-Interpreter/pull/30" target="_blank">https://github.com/MrGreyfun/Local-Code-Interpreter/pull/30</a>
                </p>
            </article>
            <article>
                <h2>Motor Imagery School Project</h2>
                <p>
                    This small school project is an introduction to scikit-learn, MNE (a Python package to process neuroimaging data), and statistics.<br>
                    In this project, we are tasked with implementing a dimensionality reduction algorithm.<br>
                    I spent a lot of time trying to implement the most commonly used CSP algorithm. While I couldn't implement it from the ground up, I was able to implement the PCA algorithm and transform a CSP implementation I found online to make it fit in the scikit-learn pipeline.<br>
                    GitHub: <a href="https://github.com/MauroAbidalCarrer/total-perspective-vortex" target="_blank">https://github.com/MauroAbidalCarrer/total-perspective-vortex</a>
                </p>
            </article>
        </section>
    </div>
</body>
</html>
